{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb1ec1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:12:29.158401Z",
     "iopub.status.busy": "2023-11-04T07:12:29.158006Z",
     "iopub.status.idle": "2023-11-04T07:12:44.298701Z",
     "shell.execute_reply": "2023-11-04T07:12:44.297654Z"
    },
    "papermill": {
     "duration": 15.161994,
     "end_time": "2023-11-04T07:12:44.301092",
     "exception": false,
     "start_time": "2023-11-04T07:12:29.139098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.33.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.0.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.15.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.23.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.2)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (3.2.4)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.16.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.9.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.6.3)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.3)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.16.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building wheels for collected packages: sentence_transformers\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=88445a39ac1ae79410438b3fca7122fc44d443c91895d84c62f8c519b0d88efc\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\r\n",
      "Successfully built sentence_transformers\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: sentence_transformers\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed sentence_transformers-2.2.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04884453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:12:44.335755Z",
     "iopub.status.busy": "2023-11-04T07:12:44.335447Z",
     "iopub.status.idle": "2023-11-04T07:12:58.537665Z",
     "shell.execute_reply": "2023-11-04T07:12:58.536878Z"
    },
    "papermill": {
     "duration": 14.222077,
     "end_time": "2023-11-04T07:12:58.539948",
     "exception": false,
     "start_time": "2023-11-04T07:12:44.317871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForQuestionAnswering, default_data_collator, get_scheduler\n",
    "import argparse\n",
    "from datasets import load_dataset\n",
    "# from transformers.models.bartpho.tokenization_bartpho_fast import BartphoTokenizerFast\n",
    "from transformers import AutoModelForQuestionAnswering, default_data_collator, get_scheduler\n",
    "from torch import nn\n",
    "# import evaluate\n",
    "import numpy as np\n",
    "from torch.optim import AdamW, Adam\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from transformers.optimization import SchedulerType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d5a2c8",
   "metadata": {
    "papermill": {
     "duration": 0.016182,
     "end_time": "2023-11-04T07:12:58.573370",
     "exception": false,
     "start_time": "2023-11-04T07:12:58.557188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce1e305",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:12:58.608093Z",
     "iopub.status.busy": "2023-11-04T07:12:58.607509Z",
     "iopub.status.idle": "2023-11-04T07:12:58.685722Z",
     "shell.execute_reply": "2023-11-04T07:12:58.684927Z"
    },
    "papermill": {
     "duration": 0.097728,
     "end_time": "2023-11-04T07:12:58.687577",
     "exception": false,
     "start_time": "2023-11-04T07:12:58.589849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c3cf84",
   "metadata": {
    "papermill": {
     "duration": 0.016274,
     "end_time": "2023-11-04T07:12:58.720746",
     "exception": false,
     "start_time": "2023-11-04T07:12:58.704472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Split data in train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de5f4a8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:12:58.756818Z",
     "iopub.status.busy": "2023-11-04T07:12:58.756491Z",
     "iopub.status.idle": "2023-11-04T07:13:02.842160Z",
     "shell.execute_reply": "2023-11-04T07:13:02.841406Z"
    },
    "papermill": {
     "duration": 4.106965,
     "end_time": "2023-11-04T07:13:02.844661",
     "exception": false,
     "start_time": "2023-11-04T07:12:58.737696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/data-process-for-evidence/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/data-process-for-evidence/test.csv')\n",
    "# val = pd.read_csv('/kaggle/input/weight-model-evidence/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7d04b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:03.990102Z",
     "iopub.status.busy": "2023-11-04T07:13:03.989775Z",
     "iopub.status.idle": "2023-11-04T07:13:04.235424Z",
     "shell.execute_reply": "2023-11-04T07:13:04.234645Z"
    },
    "papermill": {
     "duration": 0.265725,
     "end_time": "2023-11-04T07:13:04.237452",
     "exception": false,
     "start_time": "2023-11-04T07:13:03.971727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_evidence = []\n",
    "for i in test.index:\n",
    "    if test.verdict[i] =='NEI':\n",
    "        test_evidence.append(\"\")\n",
    "    else:\n",
    "        test_evidence.append(test.evidence[i])\n",
    "test.evidence = test_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c875e9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:04.352150Z",
     "iopub.status.busy": "2023-11-04T07:13:04.351815Z",
     "iopub.status.idle": "2023-11-04T07:13:04.356815Z",
     "shell.execute_reply": "2023-11-04T07:13:04.355940Z"
    },
    "papermill": {
     "duration": 0.066334,
     "end_time": "2023-11-04T07:13:04.358956",
     "exception": false,
     "start_time": "2023-11-04T07:13:04.292622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.id = range(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f263d7ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:04.392707Z",
     "iopub.status.busy": "2023-11-04T07:13:04.392453Z",
     "iopub.status.idle": "2023-11-04T07:13:04.397121Z",
     "shell.execute_reply": "2023-11-04T07:13:04.396331Z"
    },
    "papermill": {
     "duration": 0.023838,
     "end_time": "2023-11-04T07:13:04.399095",
     "exception": false,
     "start_time": "2023-11-04T07:13:04.375257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.id = range(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5203b413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:04.432574Z",
     "iopub.status.busy": "2023-11-04T07:13:04.432256Z",
     "iopub.status.idle": "2023-11-04T07:13:04.444255Z",
     "shell.execute_reply": "2023-11-04T07:13:04.443273Z"
    },
    "papermill": {
     "duration": 0.031024,
     "end_time": "2023-11-04T07:13:04.446282",
     "exception": false,
     "start_time": "2023-11-04T07:13:04.415258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data had follow weight trained with data old version 21\n",
      "\n",
      "Train: \n",
      "    NEI          35934\n",
      "    REFUTED       9410\n",
      "    SUPPORTED     8741\n",
      "Test:\n",
      "    NEI          8051\n",
      "    REFUTED      2358\n",
      "    SUPPORTED    2187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def infor_data():\n",
    "    with open('/kaggle/input/data-process-for-evidence/description.txt', 'r') as f:\n",
    "        content = f.read()\n",
    "        print(content)\n",
    "infor_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0b4893a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:04.481072Z",
     "iopub.status.busy": "2023-11-04T07:13:04.480385Z",
     "iopub.status.idle": "2023-11-04T07:13:05.710032Z",
     "shell.execute_reply": "2023-11-04T07:13:05.709253Z"
    },
    "papermill": {
     "duration": 1.249378,
     "end_time": "2023-11-04T07:13:05.712340",
     "exception": false,
     "start_time": "2023-11-04T07:13:04.462962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dict = {}\n",
    "\n",
    "for i in test.index:\n",
    "    if test.id[i] not in test_dict.keys():\n",
    "        test_dict[test.id[i] ] = [\n",
    "            {\n",
    "                'id': test.id[i],\n",
    "                'context': test.context[i],\n",
    "                'claim': test.claim[i],\n",
    "                'evidence': test.evidence[i],\n",
    "                'verdict': test.verdict[i],\n",
    "                'pre_evidence':\"++\"\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        test_dict[test.id[i] ].append(\n",
    "                {\n",
    "                    'id': test.id[i],\n",
    "                    'context': test.context[i],\n",
    "                    'claim': test.claim[i],\n",
    "                    'evidence': test.evidence[i],\n",
    "                    'verdict': test.verdict[i],\n",
    "                    'pre_evidence':\"++\"\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f948422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:05.746923Z",
     "iopub.status.busy": "2023-11-04T07:13:05.746634Z",
     "iopub.status.idle": "2023-11-04T07:13:06.319841Z",
     "shell.execute_reply": "2023-11-04T07:13:06.319075Z"
    },
    "papermill": {
     "duration": 0.592844,
     "end_time": "2023-11-04T07:13:06.322196",
     "exception": false,
     "start_time": "2023-11-04T07:13:05.729352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = Dataset.from_dict({\n",
    "    \"context\": train.context,\n",
    "    \"claim\": train['claim'],\n",
    "    \"verdict\": train.verdict,\n",
    "    \"evidence\": train.evidence,\n",
    "    \"id\": train.id,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d30eba26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:06.356594Z",
     "iopub.status.busy": "2023-11-04T07:13:06.356271Z",
     "iopub.status.idle": "2023-11-04T07:13:06.480438Z",
     "shell.execute_reply": "2023-11-04T07:13:06.479687Z"
    },
    "papermill": {
     "duration": 0.143304,
     "end_time": "2023-11-04T07:13:06.482367",
     "exception": false,
     "start_time": "2023-11-04T07:13:06.339063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = Dataset.from_dict({\n",
    "    \"context\": test.context,\n",
    "    \"claim\": test.claim,\n",
    "    \"verdict\": test.verdict,\n",
    "    \"evidence\": test.evidence,\n",
    "    \"id\": test.id,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1970b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:06.516590Z",
     "iopub.status.busy": "2023-11-04T07:13:06.516321Z",
     "iopub.status.idle": "2023-11-04T07:13:06.520908Z",
     "shell.execute_reply": "2023-11-04T07:13:06.520073Z"
    },
    "papermill": {
     "duration": 0.023723,
     "end_time": "2023-11-04T07:13:06.522770",
     "exception": false,
     "start_time": "2023-11-04T07:13:06.499047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 54085\n",
      "Test: 12596\n"
     ]
    }
   ],
   "source": [
    "print(f'Train: {len(train)}')\n",
    "print(f'Test: {len(test)}')\n",
    "# print(f'Val: {len(val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e7f451e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:06.556974Z",
     "iopub.status.busy": "2023-11-04T07:13:06.556708Z",
     "iopub.status.idle": "2023-11-04T07:13:06.564640Z",
     "shell.execute_reply": "2023-11-04T07:13:06.563762Z"
    },
    "papermill": {
     "duration": 0.027389,
     "end_time": "2023-11-04T07:13:06.566584",
     "exception": false,
     "start_time": "2023-11-04T07:13:06.539195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ade4dfa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:06.600008Z",
     "iopub.status.busy": "2023-11-04T07:13:06.599745Z",
     "iopub.status.idle": "2023-11-04T07:13:06.733096Z",
     "shell.execute_reply": "2023-11-04T07:13:06.732061Z"
    },
    "papermill": {
     "duration": 0.152345,
     "end_time": "2023-11-04T07:13:06.735057",
     "exception": false,
     "start_time": "2023-11-04T07:13:06.582712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90adeecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:06.769413Z",
     "iopub.status.busy": "2023-11-04T07:13:06.769107Z",
     "iopub.status.idle": "2023-11-04T07:13:08.545938Z",
     "shell.execute_reply": "2023-11-04T07:13:08.544959Z"
    },
    "papermill": {
     "duration": 1.79639,
     "end_time": "2023-11-04T07:13:08.548330",
     "exception": false,
     "start_time": "2023-11-04T07:13:06.751940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4398a9b1165a4f5588ee4d6206e50041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/398 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07703aef009e4d378ef1e1a454e0c4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca678745c47478c9d0e0e4883ac7f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Chọn mô hình và tải tokenizer nhanh tương ứng\n",
    "model_name = \"nguyenvulebinh/vi-mrc-base\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad64a0de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:08.584512Z",
     "iopub.status.busy": "2023-11-04T07:13:08.583948Z",
     "iopub.status.idle": "2023-11-04T07:13:08.596439Z",
     "shell.execute_reply": "2023-11-04T07:13:08.595583Z"
    },
    "papermill": {
     "duration": 0.032482,
     "end_time": "2023-11-04T07:13:08.598286",
     "exception": false,
     "start_time": "2023-11-04T07:13:08.565804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_training_dataset(examples):\n",
    "    questions = [q.strip() for q in examples[\"claim\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=512,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "#     answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        if examples[\"verdict\"][i] != \"NEI\":\n",
    "    #         answer = answers[i]\n",
    "            start_char =  examples[\"context\"][i].find(examples[\"evidence\"][i])\n",
    "            if start_char == -1:\n",
    "                print(\"Error\")\n",
    "            end_char = start_char + len(examples[\"evidence\"][i])\n",
    "            sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "            # Find the start and end of the context\n",
    "            idx = 0\n",
    "            try:\n",
    "                while sequence_ids[idx] != 1:\n",
    "                    idx += 1\n",
    "            except:\n",
    "                print(examples['id'][i])\n",
    "                print(questions[i])\n",
    "                print(\"+++++\")\n",
    "                print(examples[\"context\"][i])\n",
    "                print(\"+++++\")\n",
    "                print(sequence_ids)\n",
    "            context_start = idx\n",
    "            while sequence_ids[idx] == 1:\n",
    "                idx += 1\n",
    "            context_end = idx - 1\n",
    "\n",
    "            # If the answer is not fully inside the context, label it (0, 0)\n",
    "            if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "                start_positions.append(0)\n",
    "                end_positions.append(0)\n",
    "            else:\n",
    "                # Otherwise it's the start and end token positions\n",
    "                idx = context_start\n",
    "                while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                    idx += 1\n",
    "                start_positions.append(idx - 1)\n",
    "\n",
    "                idx = context_end\n",
    "                while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                    idx -= 1\n",
    "                end_positions.append(idx + 1)\n",
    "        else:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    inputs[\"id\"] = examples[\"id\"]\n",
    "    \n",
    "#     inputs[\"context\"] = examples[\"claim\"]\n",
    "#     inputs[\"verdict\"] = examples[\"verdict\"]\n",
    "#     inputs[\"evidence\"] = examples[\"evidence\"]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b513868d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:08.633848Z",
     "iopub.status.busy": "2023-11-04T07:13:08.633545Z",
     "iopub.status.idle": "2023-11-04T07:13:55.257133Z",
     "shell.execute_reply": "2023-11-04T07:13:55.256335Z"
    },
    "papermill": {
     "duration": 46.643283,
     "end_time": "2023-11-04T07:13:55.259006",
     "exception": false,
     "start_time": "2023-11-04T07:13:08.615723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b798659c074302990e83dcd95daa48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_squad = train.map(preprocess_training_dataset, batched=True, remove_columns=test.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b476adc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:55.295466Z",
     "iopub.status.busy": "2023-11-04T07:13:55.295152Z",
     "iopub.status.idle": "2023-11-04T07:13:55.301403Z",
     "shell.execute_reply": "2023-11-04T07:13:55.300597Z"
    },
    "papermill": {
     "duration": 0.026491,
     "end_time": "2023-11-04T07:13:55.303274",
     "exception": false,
     "start_time": "2023-11-04T07:13:55.276783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "    num_rows: 54085\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "930520bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:55.338955Z",
     "iopub.status.busy": "2023-11-04T07:13:55.338669Z",
     "iopub.status.idle": "2023-11-04T07:13:55.342468Z",
     "shell.execute_reply": "2023-11-04T07:13:55.341645Z"
    },
    "papermill": {
     "duration": 0.02393,
     "end_time": "2023-11-04T07:13:55.344284",
     "exception": false,
     "start_time": "2023-11-04T07:13:55.320354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers.optimization import SchedulerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6f6989e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:55.379810Z",
     "iopub.status.busy": "2023-11-04T07:13:55.379535Z",
     "iopub.status.idle": "2023-11-04T07:13:55.384753Z",
     "shell.execute_reply": "2023-11-04T07:13:55.384045Z"
    },
    "papermill": {
     "duration": 0.025136,
     "end_time": "2023-11-04T07:13:55.386619",
     "exception": false,
     "start_time": "2023-11-04T07:13:55.361483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    batch_size = 13\n",
    "    mode_pretrain = \"nguyenvulebinh/vi-mrc-base\"\n",
    "    '''\n",
    "    \"nguyenvulebinh/vi-mrc-base\"\n",
    "    \"deepset/xlm-roberta-large-squad2\"\n",
    "    \"vinai/phobert-base\"\n",
    "    '''\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    lr = 0.00001\n",
    "    max_answer_length = 512\n",
    "    scheduler = SchedulerType.COSINE\n",
    "    epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfd669f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:55.423257Z",
     "iopub.status.busy": "2023-11-04T07:13:55.422976Z",
     "iopub.status.idle": "2023-11-04T07:13:55.426939Z",
     "shell.execute_reply": "2023-11-04T07:13:55.426118Z"
    },
    "papermill": {
     "duration": 0.025198,
     "end_time": "2023-11-04T07:13:55.428922",
     "exception": false,
     "start_time": "2023-11-04T07:13:55.403724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e024f5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:55.464928Z",
     "iopub.status.busy": "2023-11-04T07:13:55.464668Z",
     "iopub.status.idle": "2023-11-04T07:13:55.469828Z",
     "shell.execute_reply": "2023-11-04T07:13:55.469075Z"
    },
    "papermill": {
     "duration": 0.025404,
     "end_time": "2023-11-04T07:13:55.471627",
     "exception": false,
     "start_time": "2023-11-04T07:13:55.446223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(config, epochs, model, optimizer):\n",
    "    \"\"\"\n",
    "    Function to save the trained model to disk.\n",
    "    \"\"\"\n",
    "    torch.save({\n",
    "                'epoch': epochs,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, f\"/kaggle/working/best_model.pth\")\n",
    "    print(f'Save model --> {config.mode_pretrain}_{epochs}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b436eba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:55.507717Z",
     "iopub.status.busy": "2023-11-04T07:13:55.507414Z",
     "iopub.status.idle": "2023-11-04T07:13:55.511241Z",
     "shell.execute_reply": "2023-11-04T07:13:55.510447Z"
    },
    "papermill": {
     "duration": 0.024179,
     "end_time": "2023-11-04T07:13:55.513166",
     "exception": false,
     "start_time": "2023-11-04T07:13:55.488987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47a1bf94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:13:55.549376Z",
     "iopub.status.busy": "2023-11-04T07:13:55.549076Z",
     "iopub.status.idle": "2023-11-04T07:14:52.813060Z",
     "shell.execute_reply": "2023-11-04T07:14:52.812035Z"
    },
    "papermill": {
     "duration": 57.284356,
     "end_time": "2023-11-04T07:14:52.815037",
     "exception": false,
     "start_time": "2023-11-04T07:13:55.530681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e338c56787b411980cbe394be7ad3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5594bb3035344f77b5da363bbbe34817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train.map(\n",
    "        preprocess_training_dataset,\n",
    "        batched=True,\n",
    "        remove_columns=train.column_names,\n",
    "    )\n",
    "\n",
    "test_dataset = test.map(\n",
    "    preprocess_training_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=test.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "596c00bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:14:52.852330Z",
     "iopub.status.busy": "2023-11-04T07:14:52.852000Z",
     "iopub.status.idle": "2023-11-04T07:14:53.586582Z",
     "shell.execute_reply": "2023-11-04T07:14:53.585739Z"
    },
    "papermill": {
     "duration": 0.755754,
     "end_time": "2023-11-04T07:14:53.588952",
     "exception": false,
     "start_time": "2023-11-04T07:14:52.833198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers.models.roberta.modeling_roberta import *\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cb660b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:14:53.626933Z",
     "iopub.status.busy": "2023-11-04T07:14:53.626632Z",
     "iopub.status.idle": "2023-11-04T07:14:53.639100Z",
     "shell.execute_reply": "2023-11-04T07:14:53.638392Z"
    },
    "papermill": {
     "duration": 0.034067,
     "end_time": "2023-11-04T07:14:53.640979",
     "exception": false,
     "start_time": "2023-11-04T07:14:53.606912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, dataset, config):\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_val = []\n",
    "        predictions = []\n",
    "\n",
    "        print(\"Evaluation!\")\n",
    "\n",
    "        for batch in tqdm(dataloader, total = len(dataloader)):\n",
    "            new_batch = {}\n",
    "            for key, value in batch.items():\n",
    "                if key != \"id\":\n",
    "                    new_batch[key] = value\n",
    "            batch = new_batch\n",
    "            for key in batch:\n",
    "                batch[key] = batch[key].to(config.device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss_val.append(loss.item())\n",
    "            start_logits = outputs.start_logits.cpu().numpy()\n",
    "            end_logits = outputs.end_logits.cpu().numpy()\n",
    "            start_positions = np.argmax(start_logits, axis=1)\n",
    "            end_positions = np.argmax(end_logits, axis=1)\n",
    "\n",
    "            predictions.extend(list(zip(start_positions, end_positions)))\n",
    "\n",
    "        true_start_positions = [example[\"start_positions\"] for example in dataset]\n",
    "        true_end_positions = [example[\"end_positions\"] for example in dataset]\n",
    "\n",
    "\n",
    "        # Chuyển đổi dự đoán và vị trí thực tế sang numpy array\n",
    "        predictions = np.array(predictions)\n",
    "        true_start_positions = np.array(true_start_positions)\n",
    "        true_end_positions = np.array(true_end_positions)\n",
    "        acc = []\n",
    "\n",
    "        for i in range(len(true_end_positions)):\n",
    "\n",
    "            if true_start_positions[i] == predictions[i][0] and true_end_positions[i] == predictions[i][1]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "\n",
    "        accuracy = np.sum(acc)/len(acc)\n",
    "    return round(accuracy, 4), np.sum(loss_val)/len(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "385b13fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:14:53.677251Z",
     "iopub.status.busy": "2023-11-04T07:14:53.676981Z",
     "iopub.status.idle": "2023-11-04T07:14:53.692384Z",
     "shell.execute_reply": "2023-11-04T07:14:53.691559Z"
    },
    "papermill": {
     "duration": 0.035773,
     "end_time": "2023-11-04T07:14:53.694280",
     "exception": false,
     "start_time": "2023-11-04T07:14:53.658507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def main(config, train_dataset, validation_dataset, path_weight = None):\n",
    "\n",
    "    \n",
    "   \n",
    "    train_dataset.set_format(\"torch\")\n",
    "    validation_set = validation_dataset\n",
    "    validation_set.set_format(\"torch\")\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        shuffle=True,\n",
    "        collate_fn=default_data_collator,\n",
    "        batch_size=config.batch_size,\n",
    "    )\n",
    "    \n",
    "    eval_dataloader = DataLoader(\n",
    "        validation_set,\n",
    "        collate_fn=default_data_collator,\n",
    "        batch_size=config.batch_size\n",
    "    )\n",
    "    device = torch.device(config.device)\n",
    "    print(\"+++++++\")\n",
    "    print(config.mode_pretrain)\n",
    "    print(infor_data())\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(config.mode_pretrain)\n",
    "   \n",
    "    print(\"+++++++\")\n",
    "    \n",
    "    if path_weight != None:\n",
    "        print(f'Add weight model --> {path_weight}')\n",
    "        with torch.no_grad():\n",
    "            checkpoint = torch.load(path_weight)\n",
    "            best_model_state_dict = checkpoint['model_state_dict']\n",
    "        model.load_state_dict(best_model_state_dict)\n",
    "        \n",
    "        del checkpoint\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "    model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=config.lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=config.lr, max_lr=0.001, cycle_momentum = False)\n",
    "    num_update_steps_per_epoch = len(train_dataloader)\n",
    "    num_training_steps = config.epochs * num_update_steps_per_epoch\n",
    "\n",
    "    prev_metrics = None\n",
    "    logs = []\n",
    "    best_loss = 0 \n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        # Training\n",
    "        cnt = 0\n",
    "        loss_train = []\n",
    "        loss_val = []\n",
    "        model.train()\n",
    "        acc_gradient = 2\n",
    "        for _, batch in tqdm(enumerate(train_dataloader), total =len(train_dataloader)): \n",
    "#             batch = batch.remove_columns(\"id\")\n",
    "            new_batch = {}\n",
    "            for key, value in batch.items():\n",
    "                if key != \"id\":\n",
    "                    new_batch[key] = value\n",
    "            batch = new_batch\n",
    "            for key in batch:\n",
    "                batch[key] = batch[key].to(config.device)\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss_train.append(loss.item())\n",
    "            loss.backward()\n",
    "            if (_+ 1) % acc_gradient == 0 or _ == len(train_dataloader)-1:\n",
    "                \n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step\n",
    "                \n",
    "\n",
    "\n",
    "        acc_val, loss_val = evaluate(model, eval_dataloader, validation_dataset, config)\n",
    "#         acc_train, train_val = evaluate(model, train_dataloader, train_dataset, config)\n",
    "        logs.append(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'Loss Train': np.sum(loss_train)/len(loss_train),\n",
    "                \n",
    "                'Loss Val': loss_val,\n",
    "#                 'Accuracy train':acc_train, \n",
    "                'Accuracy val': acc_val\n",
    "            }\n",
    "        )\n",
    "        print(logs[-1])\n",
    "        if acc_val > best_loss:\n",
    "            cnt=  0\n",
    "            best_loss = acc_val\n",
    "            save_model(config, epoch, model, optimizer)\n",
    "        else:\n",
    "            cnt+=1\n",
    "\n",
    "        # Mở tệp JSON để ghi dữ liệu vào\n",
    "        with open('logs.json', 'w') as json_file:\n",
    "            json.dump(logs, json_file, indent=4)\n",
    "        if cnt >=  5:\n",
    "            print(\"Stop training \")\n",
    "            return\n",
    "\n",
    "        \n",
    "        file_name = 'logs.json'\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad1a8ade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:14:53.730130Z",
     "iopub.status.busy": "2023-11-04T07:14:53.729864Z",
     "iopub.status.idle": "2023-11-04T07:14:53.989908Z",
     "shell.execute_reply": "2023-11-04T07:14:53.988880Z"
    },
    "papermill": {
     "duration": 0.280386,
     "end_time": "2023-11-04T07:14:53.992011",
     "exception": false,
     "start_time": "2023-11-04T07:14:53.711625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# del model\n",
    "# del checkpoint\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9bc06f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:14:54.033249Z",
     "iopub.status.busy": "2023-11-04T07:14:54.032922Z",
     "iopub.status.idle": "2023-11-04T07:14:54.037327Z",
     "shell.execute_reply": "2023-11-04T07:14:54.036249Z"
    },
    "papermill": {
     "duration": 0.0276,
     "end_time": "2023-11-04T07:14:54.039462",
     "exception": false,
     "start_time": "2023-11-04T07:14:54.011862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "configs = Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d23964e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:14:54.080638Z",
     "iopub.status.busy": "2023-11-04T07:14:54.080349Z",
     "iopub.status.idle": "2023-11-04T07:14:54.086400Z",
     "shell.execute_reply": "2023-11-04T07:14:54.085443Z"
    },
    "papermill": {
     "duration": 0.028993,
     "end_time": "2023-11-04T07:14:54.088494",
     "exception": false,
     "start_time": "2023-11-04T07:14:54.059501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09a7827b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:14:54.128666Z",
     "iopub.status.busy": "2023-11-04T07:14:54.128298Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2023-11-04T07:14:54.108161",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++\n",
      "nguyenvulebinh/vi-mrc-base\n",
      "\n",
      "Data had follow weight trained with data old version 21\n",
      "\n",
      "Train: \n",
      "    NEI          35934\n",
      "    REFUTED       9410\n",
      "    SUPPORTED     8741\n",
      "Test:\n",
      "    NEI          8051\n",
      "    REFUTED      2358\n",
      "    SUPPORTED    2187\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdff65a75c1f487282b0263f1e6cf762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4e1b04dbf34fc2a01619e102c21ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++\n",
      "Add weight model --> /kaggle/input/weight-for-evi/weight_evi_old21/best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337f90066ef94d9f9483369dcf092e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5290052796d3465d87e1d2213839b93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc6288421eb4e418634ff39269bc5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'Loss Train': 0.024314181903107954, 'Loss Val': 0.4854167266917745, 'Accuracy val': 0.8939}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model --> nguyenvulebinh/vi-mrc-base_0.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2935b9edfb449ad834c194d9bd0b446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042d6fff36b040dba3bec34cfcec2f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'Loss Train': 0.02219297048316692, 'Loss Val': 0.48867434718405706, 'Accuracy val': 0.8981}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model --> nguyenvulebinh/vi-mrc-base_1.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ef40b39b424118a7b5f10c125384af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f911078854244733b617f7992a1a77b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2, 'Loss Train': 0.01932727305712742, 'Loss Val': 0.5290482711959479, 'Accuracy val': 0.8963}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8c84f39c3441bda8c9ccb461cd8413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63bc6799f4b422fa91af6a54bae7146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 3, 'Loss Train': 0.01842525502709734, 'Loss Val': 0.5658941670889112, 'Accuracy val': 0.8985}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model --> nguyenvulebinh/vi-mrc-base_3.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4753fb2ea5423485c0d2eadef56d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b85b071856347eb922870f9eb63bbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 4, 'Loss Train': 0.01775698521714755, 'Loss Val': 0.5343172056329668, 'Accuracy val': 0.8949}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eae866653684172b6c01d0ff0e2411f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f971f3c133d47fd971b0204aa9d35b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 5, 'Loss Train': 0.015411014475113012, 'Loss Val': 0.5473525114858172, 'Accuracy val': 0.8941}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5438278266e439899506fe696ea59e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360af7aa0c8d4be78c84b8fa0f36b2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 6, 'Loss Train': 0.013760580696283891, 'Loss Val': 0.5342696901120724, 'Accuracy val': 0.8977}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0528f77a913b4bc292ea67b96d8b6f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fb5ba8aaf84c1491ab412713a0cfe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 7, 'Loss Train': 0.014081977281273859, 'Loss Val': 0.5488715185029528, 'Accuracy val': 0.8992}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model --> nguyenvulebinh/vi-mrc-base_7.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6046bb676541e58213521a4b527694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcd23e2ace74d8e9d239588b79840f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 8, 'Loss Train': 0.014379966382344707, 'Loss Val': 0.4943579966381325, 'Accuracy val': 0.9004}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model --> nguyenvulebinh/vi-mrc-base_8.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78078e8cdf1f42feb8f30a93b3b77d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17758a9177846f2b9a2686606224ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 9, 'Loss Train': 0.012602336343611619, 'Loss Val': 0.5816028632847373, 'Accuracy val': 0.8981}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e10fc5063d4f3d89568d9e00e923ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e9559761f64669a79be34e3a189ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 10, 'Loss Train': 0.011674066331952225, 'Loss Val': 0.5384664246896715, 'Accuracy val': 0.8985}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28b8fd7f9d94252928016ba5768f671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cfb0db282a49db96c355ba997dfdb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 11, 'Loss Train': 0.011663926546278937, 'Loss Val': 0.5364612296207769, 'Accuracy val': 0.899}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed9c76bd29b4aeea55f956244e60711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2932d2b28b45a19953cf634ce34781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 12, 'Loss Train': 0.011196715787559468, 'Loss Val': 0.6782254724981956, 'Accuracy val': 0.8955}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb1162d693d42698bfceb7545ab6c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main(configs, train_dataset, test_dataset, '/kaggle/input/weight-for-evi/weight_evi_old21/best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ef0e44",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tên tệp JSON chứa dữ liệu\n",
    "file_name = 'logs.json'\n",
    "\n",
    "# Đọc dữ liệu từ tệp JSON và chuyển thành DataFrame\n",
    "info_epoch = pd.read_json(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008beb2e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b2d86",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(info_epoch['epoch'], info_epoch['Loss Train'], label='Loss Train', marker='o')\n",
    "plt.plot(info_epoch['epoch'], info_epoch['Loss Val'], label='Loss Val', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.savefig('/kaggle/working/loss_vs_epoch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e5c0ef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "# plt.plot(info_epoch['epoch'], info_epoch['train_acc'], label='train_acc', marker='o')\n",
    "plt.plot(info_epoch['epoch'], info_epoch['Accuracy val'], label='Accuracy val', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Acc')\n",
    "plt.title('ACC vs Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.savefig('/kaggle/working/accuracy_vs_epoch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb98f1d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-04T07:12:25.819851",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
